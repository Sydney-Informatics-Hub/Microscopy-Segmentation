{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b444cb1f-a7e9-449f-96fd-78c29a5c7f8a",
   "metadata": {},
   "source": [
    "# MitoEM challenge\n",
    "This notebook takes a folder of tiff masks predictions and turns it into hd5 format for submission to [https://mitoem.grand-challenge.org/](https://mitoem.grand-challenge.org/).\n",
    "Run through the cells twice - once for Human and one for Rat. Then zip the output files together and upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8533f1df-f6f8-4e84-b42f-2d710bd978a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "import tifffile as tiff\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f404a028-e944-4c70-a1d7-48d886e96ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_dir = \"./EM30-R-im/im/\"\n",
    "# tiff_dir = \"./OUTPUT/EM30-R-all/PREDICTIONS/\"\n",
    "# h5file_name = '1_rat_instance_seg_pred.h5'\n",
    "\n",
    "data_dir = \"./EM30-H-im-pad/im_pad/\"\n",
    "tiff_dir = \"./OUTPUT/EM30-H-all/PREDICTIONS/\"\n",
    "h5file_name = '0_human_instance_seg_pred.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d54081-9528-4d29-ae18-4af068df90bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 4096, 4096)\n",
      "CPU times: total: 14.4 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read the tiff files, assume have sorteable filenames 001.tif, 002.tif etc.\n",
    "\n",
    "tiff_files = [f for f in os.listdir(tiff_dir) if f.endswith(\".tif\")]\n",
    "tiff_files.sort()\n",
    "\n",
    "# Load the first TIFF file to get its dimensions\n",
    "first_tiff = tiff.imread(os.path.join(tiff_dir, tiff_files[0]))\n",
    "height, width = first_tiff.shape\n",
    "num_slices = len(tiff_files)\n",
    "\n",
    "# Create a numpy array to store the volume\n",
    "volume = np.zeros((num_slices, height, width), dtype=np.uint8)\n",
    "\n",
    "# Iterate through TIFF files and populate a volume\n",
    "for i, tiff_file in enumerate(tiff_files):\n",
    "    #print(tiff_file)\n",
    "    tiff_data = tiff.imread(os.path.join(tiff_dir, tiff_file))\n",
    "    volume[i, :, :] = tiff_data\n",
    "    \n",
    "print(volume.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4079c7f-9ed2-4db6-8b37-6527e2a11101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Downsample the volume as required\n",
    "# volume = volume[::1,::2,::2]\n",
    "# volume = volume[::1,0:4096:1,0:4096:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f232e8-0f6f-4f51-ad48-0dd0936b4f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Smooth the data... This step is not strictly required, but may improve or worsen results.\n",
    "\n",
    "# Fill the holes\n",
    "selem = np.ones((1,1,1))\n",
    "opened_data = scipy.ndimage.binary_opening(volume, structure=selem, iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0ef2f-a175-40dd-8048-89d1eae89639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# pred_stack = (volume / 255).astype('int64')\n",
    "pred_stack, nr_objects = ndimage.label(opened_data)\n",
    "print(\"Number of objects {}\".format(nr_objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54eff0d-d78c-4b1f-a62c-6ade684c2bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e453d-d84a-4c23-a312-34d3aad6721c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Free up some memory if needed\n",
    "# volume=None\n",
    "# opened_data=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39859d-4d15-4dc6-b2b3-b40f97510041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the HDF5 file (using LZF compression to save space)\n",
    "h5f = h5py.File(h5file_name, 'w')\n",
    "h5f.create_dataset('dataset_1', data=pred_stack, compression=\"lzf\")\n",
    "h5f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1208158-eded-4253-afe7-8865c4e7e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Read the original files. These are not needed for submission, but good for diagnostics.\n",
    "data_files = [f for f in os.listdir(data_dir) if f.endswith(\".png\")]\n",
    "data_files.sort()\n",
    "\n",
    "# Subset the datafiles to just the testing images\n",
    "data_files = data_files[501:]\n",
    "\n",
    "# Load the first png file to get its dimensions\n",
    "image = Image.open(os.path.join(data_dir, data_files[0]))\n",
    "image_array = np.array(image)\n",
    "\n",
    "height, width = image_array.shape\n",
    "num_slices = len(data_files)\n",
    "\n",
    "# Create a numpy array to store the volume\n",
    "volume_data = np.zeros((num_slices, height, width), dtype=np.uint8)\n",
    "\n",
    "# Iterate through TIFF files and populate a volume\n",
    "for i, data_file in enumerate(data_files):\n",
    "    #print(tiff_file)\n",
    "    image = Image.open(os.path.join(data_dir, data_file))\n",
    "    image_array = np.array(image)\n",
    "    volume_data[i, :, :] = image_array\n",
    "    \n",
    "print(volume_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756fcc70-7851-4d61-a078-99791a34fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the volume as required\n",
    "# volume_data = volume_data[::1,::2,::2]\n",
    "# volume_data = volume_data[::1,0:4096:1,0:4096:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9724fbd-e5af-4784-aebb-e4250f9e61ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualise one of your results\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "def plot_diagnostic(gt, pred):\n",
    "    # Plottin\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    # Plot the target image\n",
    "    print(np.min(gt), np.max(gt), np.mean(gt), np.median(gt))\n",
    "    ll1=ax.imshow(gt, cmap='winter', alpha=0.5)\n",
    "\n",
    "    # Plot Prediction in red with opacity\n",
    "    print(np.min(pred), np.max(pred), np.mean(pred), np.median(pred))\n",
    "    pred_binary = np.ma.masked_where(pred == False, pred)\n",
    "    ll2=ax.imshow(pred_binary, cmap='autumn_r', alpha=0.5,vmin=0, vmax=1)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f4719-7a6b-4e8e-8575-e5120b0d8f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_diagnostic(volume_data[100,:,:], opened_data[100,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5d22c-80d6-49d9-9fb4-ef0a4463914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(volume_data[100,:,:])\n",
    "plt.show()\n",
    "plt.imshow(volume[100,:,:])\n",
    "plt.show()\n",
    "plt.imshow(opened_data[100,:,:])\n",
    "plt.show()\n",
    "plt.imshow(pred_stack[100,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9669fa5-1ae6-485a-8efd-581c9c081c85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
